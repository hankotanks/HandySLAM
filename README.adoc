== HandySLAM

Perform offline SLAM on RGBD sequences recorded with LiDAR-capable smartphones.
This project contains data loaders for scenes recorded with the 
https://github.com/strayrobots/scanner[Stray Scanner] app as well as those from the https://scannetpp.mlsg.cit.tum.de/scannetpp[ScanNet++] dataset.
Additionally, a number of helper scripts for IMU calibration with https://github.com/ethz-asl/kalibr[Kalibr].

=== Setup

HandySLAM is configured and built using `build.sh` as shown below.
This project was developed and tested only on Debian GNU/Linux 12 (bookworm) and Ubuntu 24.04.3 LTS.

[source,sh]
----
#!/bin/bash
git clone https://github.com/hankotanks/HandySLAM.git
cd HandySLAM
# build the project
chmod +x build.sh
./build.sh
----

=== Usage

[verbatim]
----
SYNOPSIS
    ./build/HandySLAM <loader> <scene_path> [--imu] [--mono] [--upscale] 
        [-o [--voxel-length] <size>] [--max-depth <threshold>]

OPTIONS
    <loader>         must be one of [scannetpp, stray]
    <scene_path>     path to scene folder
    --imu            enable IMU-integration
    --mono           use only color imagery
    --upscale        upscale depth imagery with PrompDA
    -o, --out        save TSDF volume
    --voxel-length   TSDF volume's voxel length (in meters)
    --max-depth      depth threshold
----

Once the project is built, scenes from both Stray and ScanNet++ can be processed.
For improved localization and mapping, scenes should be upscaled using PromptDA.

[source,sh]
----
#!/bin/bash
./HandySLAM stray /path/to/scene --upscale --out
----

By default, `trajectory.txt` is generated at the `<scene-path>`.
If `--out` is supplied to HandySLAM, a PLY file is saved to the same location, containing a TSDF volume mesh.

=== Calibration

HandySLAM requires a calibration profile for the device used
to record RGBD scenes. A default calibration for an iPhone 16 Pro is given in `/profiles`.
This profile should give fairly accurate results for all scans taken with the same model of iPhone.

If you have a different device, or would prefer device-specific extrinsics, 
you can generate a new profile. From Kalibr's _Camera IMU calibration_ article:

[quote, https://github.com/ethz-asl/kalibr/wiki/camera-imu-calibration]
The calibration target is fixed in this calibration and the camera-imu system is moved in front of the target to excite all IMU axes. It is important to ensure good and even illumination of the calibration target and to keep the camera shutter times low to avoid excessive motion blur.

++++

++++

I've had good results with 60 seconds of isolated excitation of all accelerometer and gyroscope axes, 
followed by 30 seconds of combined movement. Kalibr must be installed through docker for the included
calibration scripts to succeed.

[source,sh]
----
#!/bin/bash
chmod +x ./scripts/calibrate_stray_with_aprilgrid.sh
# Usage: ./scripts/calibrate_stray_with_aprilgrid.sh <scene_path> <profile_name> 
#          <tagCols> <tagRows> <tagSize> <tagSpacing> 
#          <accelerometer_noise_density> <accelerometer_random_walk> <gyroscope_noise_density> <gyroscope_random_walk>
# Below: calibrate using a Stray scene of a 6x6 april grid with 3.9cm tags spaced 9mm apart
# the final 4 parameters are IMU noise parameters
./scripts/calibrate_stray_with_aprilgrid.sh ../1db4db4bec/1db4db4bec/ iphone16pro 6 6 0.039 0.009 1.4e-2 2.5e-3 5.1e-3 5e-4
----